# Lerian MCP Memory Server - Configuration
# Copy this file to .env and update the values as needed
# 
# This file is the single source of truth for all configuration
# All variables are automatically passed to Docker containers via env_file

# ================================================================
# REQUIRED - API & EMBEDDING
# ================================================================

# OpenAI Configuration (Required for embeddings)
# This defaults to your global OPENAI_API_KEY environment variable
# If you don't have a global OPENAI_API_KEY set, replace with your actual key
OPENAI_API_KEY=${OPENAI_API_KEY:-your_openai_api_key_here}
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002

# ================================================================
# SERVER CONFIGURATION
# ================================================================

# Server ports
MCP_HOST_PORT=9080                    # Main MCP API port
MCP_HEALTH_PORT=9081                  # Health check endpoint
MCP_METRICS_PORT=9082                 # Metrics endpoint (optional)

# Server host
MCP_MEMORY_HOST=localhost

# ================================================================
# VECTOR DATABASE (QDRANT)
# ================================================================

# Qdrant Vector Database ports
QDRANT_HOST_PORT=6333                 # Qdrant HTTP API
QDRANT_GRPC_PORT=6334                 # Qdrant gRPC API

# Vector configuration
QDRANT_COLLECTION=claude_memory       # Collection name
MCP_MEMORY_EMBEDDING_DIMENSION=1536   # Embedding dimension (ada-002)

# ================================================================
# STORAGE & DATA
# ================================================================

# PostgreSQL database configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=lerian_mcp_memory
DB_USER=postgres
DB_PASSWORD=postgres
DB_SSLMODE=disable
DB_MAX_OPEN_CONNS=25
DB_MAX_IDLE_CONNS=5

# PostgreSQL Docker service configuration (for monitoring profile)
POSTGRES_DB=lerian_mcp_memory
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_PORT=5432

# SQLite metadata storage (fallback)
SQLITE_DB_PATH=/app/data/memory.db

# Data retention
RETENTION_DAYS=90

# ================================================================
# LOGGING & MONITORING  
# ================================================================

# Logging configuration
MCP_MEMORY_LOG_LEVEL=info             # debug, info, warn, error
LOG_FORMAT=json

# Health checks
HEALTH_CHECK_INTERVAL=30s
HEALTH_CHECK_TIMEOUT=10s
HEALTH_CHECK_RETRIES=3

# ================================================================
# SECURITY & BACKUP
# ================================================================

# Security settings
MCP_MEMORY_ENCRYPTION_ENABLED=true
MCP_MEMORY_ACCESS_CONTROL_ENABLED=true

# Backup configuration
MCP_MEMORY_BACKUP_ENABLED=true
MCP_MEMORY_BACKUP_INTERVAL_HOURS=24

# ================================================================
# MCP PROTOCOL CONFIGURATION
# ================================================================

# CORS settings (for web clients)
MCP_MEMORY_CORS_ENABLED=true
MCP_MEMORY_CORS_ORIGINS=http://localhost:*,https://localhost:*

# Protocol support
MCP_STDIO_ENABLED=true                # stdio + proxy support
MCP_HTTP_ENABLED=true                 # Direct HTTP JSON-RPC
MCP_WS_ENABLED=true                   # WebSocket support
MCP_SSE_ENABLED=true                  # Server-Sent Events

# MCP proxy configuration (for stdio clients)
MCP_SERVER_HOST=localhost
MCP_SERVER_PORT=9080
MCP_SERVER_PATH=/mcp
MCP_PROXY_DEBUG=false

# ================================================================
# MONITORING AND OBSERVABILITY
# ================================================================

# Monitoring configuration for production deployments
MONITORING_ENABLED=true
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
GRAFANA_USER=admin
GRAFANA_PASSWORD=change_me_please
ALERTMANAGER_PORT=9093
NODE_EXPORTER_PORT=9100

# Performance monitoring
PERFORMANCE_MONITORING_ENABLED=true
METRICS_RETENTION_DAYS=30
ALERT_THRESHOLD_MEMORY=85
ALERT_THRESHOLD_CPU=80

# Alert notification (configure one or more)
# ALERT_WEBHOOK_URL=https://hooks.slack.com/your-webhook
# ALERT_EMAIL_TO=alerts@yourcompany.com
# ALERT_EMAIL_FROM=mcp-memory@yourcompany.com
# ALERT_EMAIL_SMTP_HOST=smtp.yourcompany.com
# ALERT_EMAIL_SMTP_PORT=587
# ALERT_EMAIL_SMTP_USER=username
# ALERT_EMAIL_SMTP_PASSWORD=password

# ================================================================
# OPTIONAL - ADVANCED FEATURES
# ================================================================

# Multi-repository support
MCP_MEMORY_MAX_REPOSITORIES=100
MCP_MEMORY_ENABLE_TEAM_LEARNING=true

# Pattern recognition  
MCP_MEMORY_PATTERN_MIN_FREQUENCY=3
MCP_MEMORY_REPO_SIMILARITY_THRESHOLD=0.6

# Performance optimization
MCP_MEMORY_VECTOR_CACHE_MAX_SIZE=1000
MCP_MEMORY_QUERY_CACHE_TTL_MINUTES=15

# Circuit breaker settings (production safety)
MCP_MEMORY_CIRCUIT_BREAKER_ENABLED=true
MCP_MEMORY_CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
MCP_MEMORY_CIRCUIT_BREAKER_TIMEOUT_SECONDS=60

# Circuit breaker configuration for different services
# API service: More lenient thresholds for general API operations
# Health service: Very lenient for health checks to avoid cascade failures
# Vector storage: Circuit breaker protection for Qdrant operations
# AI service: Built-in circuit breaker for AI provider calls

# Production safety features enabled:
# - Vector store circuit breakers and retry logic
# - AI service circuit breaker protection  
# - API middleware circuit breakers for HTTP endpoints
# - Rate limiting for embedding API calls
# - Request timeout and recovery middleware

# ================================================================
# AUTO-UPDATE SETTINGS (WATCHTOWER)
# ================================================================

# How often to check for updates (seconds)
WATCHTOWER_POLL_INTERVAL=300         # 5 minutes

# Set to false to disable automatic updates
WATCHTOWER_LABEL_ENABLE=true

# Remove old images after updating
WATCHTOWER_CLEANUP=true

# ================================================================
# DATABASE TUNING (OPTIONAL)
# ================================================================

# Storage provider
MCP_MEMORY_STORAGE_PROVIDER=qdrant
MCP_MEMORY_DB_TYPE=sqlite

# Performance settings
MCP_MEMORY_MAX_CONNECTIONS=10
MCP_MEMORY_CONNECTION_TIMEOUT_SECONDS=30
MCP_MEMORY_QUERY_TIMEOUT_SECONDS=60

# ================================================================
# AI SERVICE CONFIGURATION
# ================================================================

# CRITICAL: Choose your AI provider for document generation (PRD/TRD/Tasks)
# Without this, the system defaults to mock AI services

# Primary AI Provider Selection (REQUIRED for real AI)
AI_PROVIDER=openai                    # Options: openai, claude, perplexity, mock
# AI_API_KEY=your_generic_api_key     # Generic API key (fallback)
# AI_BASE_URL=custom_base_url         # Custom API endpoint (optional)
# AI_MODEL=custom_model               # Override default model selection

# ================================================================
# OPENAI CONFIGURATION
# ================================================================

# OpenAI Settings (API key already configured above for embeddings)
# OPENAI_ENABLED=true                 # Legacy flag (not used by new AI system)
OPENAI_MODEL=gpt-4o                   # Model: gpt-4o, gpt-4o-mini, gpt-3.5-turbo
# OPENAI_BASE_URL=https://api.openai.com/v1  # Custom OpenAI endpoint

# OpenAI Advanced Settings
# MCP_MEMORY_OPENAI_MAX_TOKENS=8191         # Max tokens per request
# MCP_MEMORY_OPENAI_TEMPERATURE=0.0         # Creativity level (0.0-2.0)
# MCP_MEMORY_OPENAI_REQUEST_TIMEOUT_SECONDS=60  # Request timeout
# MCP_MEMORY_OPENAI_RATE_LIMIT_RPM=60       # Rate limit per minute

# ================================================================
# CLAUDE CONFIGURATION
# ================================================================

# Claude/Anthropic Settings
# CLAUDE_ENABLED=true                 # Legacy flag (not used by new AI system)
# CLAUDE_API_KEY=your_claude_api_key_here           # Claude API key
# ANTHROPIC_API_KEY=your_anthropic_api_key_here     # Alternative key name
# CLAUDE_MODEL=claude-sonnet-4        # Model: claude-sonnet-4, claude-3-5-sonnet-20241022
# CLAUDE_BASE_URL=https://api.anthropic.com        # Claude API endpoint

# ================================================================
# PERPLEXITY CONFIGURATION
# ================================================================

# Perplexity Settings
# PERPLEXITY_ENABLED=true             # Legacy flag (not used by new AI system)
# PERPLEXITY_API_KEY=your_perplexity_api_key_here  # Perplexity API key
# PERPLEXITY_MODEL=sonar-pro          # Model: sonar-pro, sonar-medium, etc.
# PERPLEXITY_BASE_URL=https://api.perplexity.ai    # Perplexity API endpoint

# ================================================================
# CLI (LMMC) CONFIGURATION
# ================================================================

# CLI-specific environment variables (prefixed with LMMC_)
# These are read by the lmmc binary for client-side configuration

# Server Connection
# LMMC_SERVER_URL=http://localhost:9080        # MCP server URL
# LMMC_SERVER_VERSION=v1                       # API version
# LMMC_SERVER_TIMEOUT=30                       # Connection timeout (seconds)

# CLI Behavior  
# LMMC_CLI_DEFAULT_REPOSITORY=current          # Default repository
# LMMC_CLI_OUTPUT_FORMAT=table                 # Output: table, json, yaml
# LMMC_CLI_AUTO_COMPLETE=true                  # Enable auto-completion
# LMMC_CLI_COLOR_SCHEME=auto                   # Colors: auto, light, dark, none
# LMMC_CLI_PAGE_SIZE=20                        # Pagination size
# LMMC_CLI_EDITOR=nano                         # Default text editor

# CLI Storage & Caching
# LMMC_STORAGE_CACHE_ENABLED=true              # Enable local caching
# LMMC_STORAGE_CACHE_TTL=300                   # Cache TTL (seconds)
# LMMC_STORAGE_BACKUP_COUNT=3                  # Number of backups to keep
# LMMC_CONFIG_DIR=/custom/config/path          # Custom config directory

# CLI Logging
# LMMC_LOGGING_LEVEL=info                      # Log level: debug, info, warn, error
# LMMC_LOGGING_FORMAT=text                     # Format: text, json
# LMMC_LOGGING_FILE=/path/to/lmmc.log          # Log file path (optional)

# Note: If no AI provider is configured, the system will use mock AI services
# Mock services generate placeholder content for testing and development
