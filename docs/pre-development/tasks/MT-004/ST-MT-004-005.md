# ST-MT-004-005: Create Workflow Analytics and Visualization

## 1. Sub-Task Overview
- **Sub-Task ID:** ST-MT-004-005
- **Sub-Task Name:** Create Workflow Analytics and Visualization
- **Parent Task:** MT-004: Intelligence Features and Pattern Learning
- **Estimated Duration:** 3 hours
- **Implementation Type:** Code

## 2. Deliverable Specification
- **Primary Output:** Analytics dashboard with workflow visualization, productivity metrics, and trend analysis
- **Code Location:** 
  - `cli/internal/adapters/primary/commands/analytics.go` - Analytics CLI commands
  - `cli/internal/domain/services/analytics_service.go` - Analytics calculations
  - `cli/internal/adapters/secondary/visualization/charts.go` - Chart generation
  - `cli/internal/adapters/secondary/visualization/reports.go` - Report generation
  - `cli/internal/domain/entities/metrics.go` - Metric entities
- **Technical Requirements:** Data aggregation, chart rendering, trend analysis, report generation
- **Interface Definition:** AnalyticsService interface, visualization components, export formats

## 3. Implementation Details
- **Step-by-Step Approach:**
  1. Create metric entity structures for analytics
  2. Implement analytics service with calculations
  3. Add productivity metric calculations
  4. Create visualization components for terminal
  5. Implement trend analysis algorithms
  6. Add workflow bottleneck detection
  7. Create report generation in multiple formats
  8. Implement time-based filtering and grouping
  9. Add comparative analytics across periods
  10. Create export functionality

- **Code Examples:**
  ```go
  // Metric entities
  package entities
  
  type MetricType string
  
  const (
      MetricTypeProductivity   MetricType = "productivity"
      MetricTypeCompletion     MetricType = "completion"
      MetricTypeVelocity       MetricType = "velocity"
      MetricTypeCycleTime      MetricType = "cycle_time"
      MetricTypeEfficiency     MetricType = "efficiency"
      MetricTypeQuality        MetricType = "quality"
  )
  
  type WorkflowMetrics struct {
      Repository      string                 `json:"repository"`
      Period          TimePeriod             `json:"period"`
      Productivity    ProductivityMetrics    `json:"productivity"`
      Completion      CompletionMetrics      `json:"completion"`
      Velocity        VelocityMetrics        `json:"velocity"`
      CycleTime       CycleTimeMetrics       `json:"cycle_time"`
      Patterns        PatternMetrics         `json:"patterns"`
      Bottlenecks     []Bottleneck           `json:"bottlenecks"`
      Trends          TrendAnalysis          `json:"trends"`
      Comparisons     PeriodComparison       `json:"comparisons"`
      GeneratedAt     time.Time              `json:"generated_at"`
  }
  
  type ProductivityMetrics struct {
      Score           float64                `json:"score"`           // 0-100 overall score
      TasksPerDay     float64                `json:"tasks_per_day"`
      FocusTime       time.Duration          `json:"focus_time"`      // Uninterrupted work time
      PeakHours       []int                  `json:"peak_hours"`      // Most productive hours
      ByPriority      map[string]float64     `json:"by_priority"`     // Completion by priority
      ByType          map[string]float64     `json:"by_type"`         // Completion by task type
  }
  
  type CompletionMetrics struct {
      TotalTasks      int                    `json:"total_tasks"`
      Completed       int                    `json:"completed"`
      InProgress      int                    `json:"in_progress"`
      Cancelled       int                    `json:"cancelled"`
      CompletionRate  float64                `json:"completion_rate"`
      AverageTime     time.Duration          `json:"average_time"`
      ByStatus        map[string]int         `json:"by_status"`
  }
  
  type VelocityMetrics struct {
      CurrentVelocity float64                `json:"current_velocity"` // Tasks/week
      TrendDirection  string                 `json:"trend_direction"`  // up, down, stable
      TrendPercentage float64                `json:"trend_percentage"`
      ByWeek          []WeeklyVelocity       `json:"by_week"`
      Forecast        VelocityForecast       `json:"forecast"`
  }
  
  type Bottleneck struct {
      Type            string                 `json:"type"`            // task_type, time_of_day, dependency
      Description     string                 `json:"description"`
      Impact          float64                `json:"impact"`          // Hours lost
      Frequency       int                    `json:"frequency"`       // Occurrences
      Suggestions     []string               `json:"suggestions"`
  }
  
  type TrendAnalysis struct {
      ProductivityTrend   Trend              `json:"productivity_trend"`
      VelocityTrend       Trend              `json:"velocity_trend"`
      QualityTrend        Trend              `json:"quality_trend"`
      Predictions         []Prediction        `json:"predictions"`
  }
  
  // Analytics service
  type AnalyticsService interface {
      GetWorkflowMetrics(ctx context.Context, repository string, period TimePeriod) (*WorkflowMetrics, error)
      GetProductivityReport(ctx context.Context, repository string) (*ProductivityReport, error)
      DetectBottlenecks(ctx context.Context, repository string) ([]*Bottleneck, error)
      ComparePeriods(ctx context.Context, repository string, period1, period2 TimePeriod) (*PeriodComparison, error)
      GenerateVisualization(ctx context.Context, metrics *WorkflowMetrics, format VisFormat) ([]byte, error)
      ExportAnalytics(ctx context.Context, repository string, format ExportFormat) (string, error)
  }
  
  type analyticsServiceImpl struct {
      taskStore       storage.TaskStorage
      patternStore    storage.PatternStorage
      sessionStore    storage.SessionStorage
      calculator      *MetricsCalculator
      visualizer      Visualizer
      logger          *slog.Logger
  }
  
  func (a *analyticsServiceImpl) GetWorkflowMetrics(
      ctx context.Context,
      repository string,
      period TimePeriod,
  ) (*WorkflowMetrics, error) {
      // Get tasks for period
      tasks, err := a.taskStore.GetByPeriod(ctx, repository, period)
      if err != nil {
          return nil, err
      }
      
      // Get sessions for period
      sessions, err := a.sessionStore.GetByPeriod(ctx, repository, period)
      if err != nil {
          return nil, err
      }
      
      // Calculate metrics
      metrics := &WorkflowMetrics{
          Repository:   repository,
          Period:       period,
          GeneratedAt:  time.Now(),
      }
      
      // Productivity metrics
      metrics.Productivity = a.calculateProductivity(tasks, sessions)
      
      // Completion metrics
      metrics.Completion = a.calculateCompletion(tasks)
      
      // Velocity metrics
      metrics.Velocity = a.calculateVelocity(tasks, period)
      
      // Cycle time metrics
      metrics.CycleTime = a.calculateCycleTime(tasks)
      
      // Pattern metrics
      patterns, _ := a.patternStore.GetByRepository(ctx, repository)
      metrics.Patterns = a.calculatePatternMetrics(patterns)
      
      // Detect bottlenecks
      metrics.Bottlenecks = a.detectBottlenecks(tasks, sessions)
      
      // Trend analysis
      metrics.Trends = a.analyzeTrends(repository, period)
      
      return metrics, nil
  }
  
  func (a *analyticsServiceImpl) calculateProductivity(
      tasks []*Task,
      sessions []*Session,
  ) ProductivityMetrics {
      metrics := ProductivityMetrics{
          ByPriority: make(map[string]float64),
          ByType:     make(map[string]float64),
      }
      
      // Calculate tasks per day
      if len(sessions) > 0 {
          totalDays := float64(len(sessions))
          completedTasks := 0
          for _, task := range tasks {
              if task.Status == "completed" {
                  completedTasks++
              }
          }
          metrics.TasksPerDay = float64(completedTasks) / totalDays
      }
      
      // Calculate focus time
      totalFocusTime := time.Duration(0)
      peakHours := make(map[int]int)
      
      for _, session := range sessions {
          // Focus time is continuous work without long breaks
          focusPeriods := a.extractFocusPeriods(session)
          for _, period := range focusPeriods {
              totalFocusTime += period.Duration
              hour := period.StartTime.Hour()
              peakHours[hour]++
          }
      }
      
      metrics.FocusTime = totalFocusTime / time.Duration(len(sessions))
      
      // Find peak hours
      var topHours []int
      for hour, count := range peakHours {
          if count > len(sessions)/4 { // Active in >25% of sessions
              topHours = append(topHours, hour)
          }
      }
      sort.Ints(topHours)
      metrics.PeakHours = topHours
      
      // Calculate by priority
      priorityCounts := make(map[string]int)
      priorityCompleted := make(map[string]int)
      
      for _, task := range tasks {
          priorityCounts[task.Priority]++
          if task.Status == "completed" {
              priorityCompleted[task.Priority]++
          }
      }
      
      for priority, count := range priorityCounts {
          if count > 0 {
              metrics.ByPriority[priority] = float64(priorityCompleted[priority]) / float64(count)
          }
      }
      
      // Calculate overall score
      metrics.Score = a.calculateProductivityScore(metrics, tasks, sessions)
      
      return metrics
  }
  
  // Visualization components
  type Visualizer interface {
      RenderProductivityChart(metrics ProductivityMetrics) string
      RenderVelocityChart(metrics VelocityMetrics) string
      RenderCompletionChart(metrics CompletionMetrics) string
      RenderBottlenecks(bottlenecks []*Bottleneck) string
      RenderTrends(trends TrendAnalysis) string
  }
  
  type terminalVisualizer struct {
      width  int
      height int
      colors bool
  }
  
  func (v *terminalVisualizer) RenderProductivityChart(metrics ProductivityMetrics) string {
      // Create ASCII bar chart for productivity
      var builder strings.Builder
      
      builder.WriteString("📊 Productivity Score: ")
      builder.WriteString(v.renderProgressBar(metrics.Score, 100))
      builder.WriteString(fmt.Sprintf(" %.1f%%\n\n", metrics.Score))
      
      builder.WriteString("📈 Tasks per Day: %.1f\n", metrics.TasksPerDay)
      builder.WriteString("⏱️  Average Focus Time: %s\n\n", metrics.FocusTime)
      
      builder.WriteString("Priority Completion Rates:\n")
      for _, priority := range []string{"high", "medium", "low"} {
          if rate, exists := metrics.ByPriority[priority]; exists {
              builder.WriteString(fmt.Sprintf("  %s: ", priority))
              builder.WriteString(v.renderMiniBar(rate))
              builder.WriteString(fmt.Sprintf(" %.0f%%\n", rate*100))
          }
      }
      
      builder.WriteString("\n🕐 Peak Productivity Hours: ")
      for i, hour := range metrics.PeakHours {
          if i > 0 {
              builder.WriteString(", ")
          }
          builder.WriteString(fmt.Sprintf("%02d:00", hour))
      }
      builder.WriteString("\n")
      
      return builder.String()
  }
  
  func (v *terminalVisualizer) RenderVelocityChart(metrics VelocityMetrics) string {
      var builder strings.Builder
      
      // Velocity trend indicator
      trendIcon := "→"
      if metrics.TrendDirection == "up" {
          trendIcon = "↗"
      } else if metrics.TrendDirection == "down" {
          trendIcon = "↘"
      }
      
      builder.WriteString(fmt.Sprintf("📏 Current Velocity: %.1f tasks/week %s %.1f%%\n\n",
          metrics.CurrentVelocity, trendIcon, metrics.TrendPercentage))
      
      // Weekly velocity chart
      builder.WriteString("Weekly Velocity:\n")
      maxVelocity := 0.0
      for _, week := range metrics.ByWeek {
          if week.Velocity > maxVelocity {
              maxVelocity = week.Velocity
          }
      }
      
      for _, week := range metrics.ByWeek {
          builder.WriteString(fmt.Sprintf("W%02d: ", week.Number))
          barLength := int((week.Velocity / maxVelocity) * 30)
          builder.WriteString(strings.Repeat("█", barLength))
          builder.WriteString(fmt.Sprintf(" %.1f\n", week.Velocity))
      }
      
      // Forecast
      if metrics.Forecast.Confidence > 0.7 {
          builder.WriteString(fmt.Sprintf("\n🔮 Next Week Forecast: %.1f tasks (%.0f%% confidence)\n",
              metrics.Forecast.PredictedVelocity, metrics.Forecast.Confidence*100))
      }
      
      return builder.String()
  }
  
  func (v *terminalVisualizer) renderProgressBar(value, max float64) string {
      percentage := value / max
      filled := int(percentage * 20)
      empty := 20 - filled
      
      bar := strings.Repeat("█", filled) + strings.Repeat("░", empty)
      
      if v.colors {
          if percentage >= 0.8 {
              return fmt.Sprintf("\033[32m%s\033[0m", bar) // Green
          } else if percentage >= 0.6 {
              return fmt.Sprintf("\033[33m%s\033[0m", bar) // Yellow
          } else {
              return fmt.Sprintf("\033[31m%s\033[0m", bar) // Red
          }
      }
      
      return bar
  }
  
  // Analytics command
  func NewAnalyticsCommand(deps CommandDeps) *cobra.Command {
      cmd := &cobra.Command{
          Use:   "analytics [repository]",
          Short: "View productivity analytics and insights",
          Long:  "Display comprehensive analytics including productivity metrics, velocity trends, and workflow bottlenecks",
          RunE: func(cmd *cobra.Command, args []string) error {
              repository := deps.Config.GetCurrentRepository()
              if len(args) > 0 {
                  repository = args[0]
              }
              
              period := TimePeriod{
                  Start: time.Now().AddDate(0, 0, -30), // Last 30 days
                  End:   time.Now(),
              }
              
              // Get metrics
              metrics, err := deps.AnalyticsService.GetWorkflowMetrics(
                  cmd.Context(), repository, period)
              if err != nil {
                  return err
              }
              
              // Create visualizer
              visualizer := NewTerminalVisualizer()
              
              // Render dashboard
              fmt.Println("📊 Workflow Analytics Dashboard")
              fmt.Println("================================\n")
              
              fmt.Println(visualizer.RenderProductivityChart(metrics.Productivity))
              fmt.Println(visualizer.RenderVelocityChart(metrics.Velocity))
              fmt.Println(visualizer.RenderCompletionChart(metrics.Completion))
              
              if len(metrics.Bottlenecks) > 0 {
                  fmt.Println(visualizer.RenderBottlenecks(metrics.Bottlenecks))
              }
              
              fmt.Println(visualizer.RenderTrends(metrics.Trends))
              
              // Export option
              export, _ := cmd.Flags().GetString("export")
              if export != "" {
                  filename, err := deps.AnalyticsService.ExportAnalytics(
                      cmd.Context(), repository, ExportFormat(export))
                  if err != nil {
                      return err
                  }
                  fmt.Printf("\n📄 Analytics exported to: %s\n", filename)
              }
              
              return nil
          },
      }
      
      cmd.Flags().StringP("period", "p", "30d", "Time period (7d, 30d, 90d)")
      cmd.Flags().StringP("export", "e", "", "Export format (json, csv, pdf)")
      cmd.Flags().BoolP("compare", "c", false, "Compare with previous period")
      
      return cmd
  }
  ```

- **Configuration Changes:** 
  - Add analytics calculation intervals
  - Configure visualization preferences
  - Set export format options

- **Dependencies:**
  - Terminal UI library for charts
  - Export libraries (CSV, PDF generation)

## 4. Acceptance Criteria
- **Functional Criteria:**
  - Analytics accurately reflect task completion data
  - Visualizations render correctly in terminal
  - Trend analysis provides meaningful insights
  - Bottleneck detection identifies real issues
  - Export formats are properly formatted
  - Time period filtering works correctly
  - Comparative analytics show clear differences
  
- **Technical Criteria:**
  - Analytics calculation completes in <5 seconds
  - Visualizations adapt to terminal size
  - Export files are valid and complete
  - Memory efficient for large datasets
  
- **Integration Criteria:**
  - Uses data from all previous sub-tasks
  - Works with existing task and session data
  - Compatible with CLI command structure
  
- **Test Criteria:**
  - Metric calculations verified against known data
  - Visualization rendering tested
  - Export format validation
  - Performance benchmarks met

## 5. Testing Requirements
- **Unit Tests:**
  - Metric calculation accuracy
  - Trend analysis algorithms
  - Bottleneck detection logic
  - Visualization rendering
  - Export format generation
  - Time period calculations
  
- **Integration Tests:**
  - Full analytics generation flow
  - Data aggregation from multiple sources
  - Export functionality
  - CLI command execution
  
- **Manual Testing:**
  - Visual inspection of charts
  - Export file validation
  - Different terminal sizes
  - Various data scenarios
  
- **Test Data:**
  - Task datasets with known metrics
  - Session data samples
  - Edge cases (no data, single task)
  - Large datasets for performance

## 6. Definition of Done
- **Code Complete:** Analytics service with visualization implemented
- **Tests Passing:** All unit and integration tests passing (≥85% coverage)
- **Documentation Updated:** Analytics interpretation guide created
- **Integration Verified:** Works with all MT-004 components
- **Review Approved:** UX review of visualizations completed

## 7. Dependencies and Blockers
- **Required Sub-Tasks:** All previous MT-004 sub-tasks for data sources
- **External Dependencies:** Terminal UI library, export libraries
- **Environmental Requirements:** Terminal with UTF-8 support
- **Potential Blockers:** Terminal compatibility for advanced charts

## 8. Integration Notes
- **Component Interfaces:** Used by CLI analytics command
- **Data Flow:** Task/Session Data → Calculations → Visualization → Output
- **Error Handling:** Graceful handling of missing data
- **Configuration Impact:** New analytics display preferences