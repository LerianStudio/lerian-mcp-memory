# ST-MT-004-004: Implement Cross-Repository Learning and Insights

## 1. Sub-Task Overview
- **Sub-Task ID:** ST-MT-004-004
- **Sub-Task Name:** Implement Cross-Repository Learning and Insights
- **Parent Task:** MT-004: Intelligence Features and Pattern Learning
- **Estimated Duration:** 4 hours
- **Implementation Type:** Code

## 2. Deliverable Specification
- **Primary Output:** Cross-repository pattern learning system with aggregated insights and shared knowledge
- **Code Location:** 
  - `cli/internal/domain/services/cross_repo_analyzer.go` - Cross-repo analysis service
  - `cli/internal/domain/entities/insights.go` - Insight entities
  - `cli/internal/adapters/secondary/learning/aggregator.go` - Pattern aggregation
  - `cli/internal/adapters/secondary/learning/similarity.go` - Repository similarity
  - `internal/intelligence/multi_repo_engine.go` - Server-side multi-repo engine
- **Technical Requirements:** Pattern aggregation, similarity analysis, privacy-preserving learning, insight generation
- **Interface Definition:** CrossRepoAnalyzer interface, similarity algorithms, privacy controls

## 3. Implementation Details
- **Step-by-Step Approach:**
  1. Create insight entity structures for cross-repo knowledge
  2. Implement repository similarity analysis
  3. Create pattern aggregation with privacy controls
  4. Develop cross-repository learning algorithms
  5. Add anonymization for sensitive patterns
  6. Implement insight generation from aggregated data
  7. Create similarity-based recommendation engine
  8. Add opt-in/opt-out controls for sharing
  9. Implement insight ranking and filtering
  10. Create insight persistence and caching

- **Code Examples:**
  ```go
  // Insight entities
  package entities
  
  type InsightType string
  
  const (
      InsightTypePattern      InsightType = "pattern"
      InsightTypeWorkflow     InsightType = "workflow"
      InsightTypeBestPractice InsightType = "best_practice"
      InsightTypeAntiPattern  InsightType = "anti_pattern"
      InsightTypeTrend        InsightType = "trend"
      InsightTypeOptimization InsightType = "optimization"
  )
  
  type CrossRepoInsight struct {
      ID               string                 `json:"id" validate:"required,uuid"`
      Type             InsightType            `json:"type" validate:"required"`
      Title            string                 `json:"title" validate:"required,min=1,max=200"`
      Description      string                 `json:"description"`
      Pattern          *AnonymizedPattern     `json:"pattern,omitempty"`
      SourceCount      int                    `json:"source_count"`      // Number of repos contributing
      Confidence       float64                `json:"confidence"`        // 0-1 confidence score
      Relevance        float64                `json:"relevance"`         // 0-1 relevance to current repo
      Impact           ImpactMetrics          `json:"impact"`
      Applicability    []string               `json:"applicability"`     // Project types this applies to
      Prerequisites    []string               `json:"prerequisites"`
      Recommendations  []string               `json:"recommendations"`
      Tags             []string               `json:"tags"`
      Metadata         map[string]interface{} `json:"metadata"`
      GeneratedAt      time.Time              `json:"generated_at"`
      ValidUntil       time.Time              `json:"valid_until"`
      IsActionable     bool                   `json:"is_actionable"`
  }
  
  type AnonymizedPattern struct {
      Type            string                 `json:"type"`
      Sequence        []string               `json:"sequence"`         // Generalized task types
      Frequency       float64                `json:"frequency"`
      SuccessRate     float64                `json:"success_rate"`
      TimeMetrics     TimeMetrics            `json:"time_metrics"`
      CommonKeywords  []string               `json:"common_keywords"`
      ProjectTypes    []string               `json:"project_types"`
  }
  
  type ImpactMetrics struct {
      ProductivityGain    float64 `json:"productivity_gain"`    // Percentage improvement
      TimeReduction       float64 `json:"time_reduction"`       // Hours saved
      QualityImprovement  float64 `json:"quality_improvement"`  // Bug reduction %
      AdoptionRate        float64 `json:"adoption_rate"`        // % of repos using
  }
  
  type RepositorySimilarity struct {
      RepositoryA     string                 `json:"repository_a"`
      RepositoryB     string                 `json:"repository_b"`
      Score           float64                `json:"score"`            // 0-1 similarity
      Dimensions      SimilarityDimensions   `json:"dimensions"`
      SharedPatterns  []string               `json:"shared_patterns"`  // Pattern IDs
      LastCalculated  time.Time              `json:"last_calculated"`
  }
  
  type SimilarityDimensions struct {
      ProjectType     float64 `json:"project_type"`
      TechStack       float64 `json:"tech_stack"`
      TeamSize        float64 `json:"team_size"`
      Complexity      float64 `json:"complexity"`
      Domain          float64 `json:"domain"`
      WorkPatterns    float64 `json:"work_patterns"`
  }
  
  // Cross-repository analyzer
  type CrossRepoAnalyzer interface {
      AnalyzeCrossRepoPatterns(ctx context.Context, repository string) ([]*CrossRepoInsight, error)
      FindSimilarRepositories(ctx context.Context, repository string, limit int) ([]*RepositorySimilarity, error)
      GetSharedInsights(ctx context.Context, projectType ProjectType) ([]*CrossRepoInsight, error)
      ContributePattern(ctx context.Context, pattern *TaskPattern, optIn bool) error
      GetInsightRecommendations(ctx context.Context, repository string) ([]*CrossRepoInsight, error)
      CalculateRepositorySimilarity(ctx context.Context, repoA, repoB string) (*RepositorySimilarity, error)
  }
  
  type PrivacySettings struct {
      SharePatterns       bool     `json:"share_patterns"`
      ShareMetrics        bool     `json:"share_metrics"`
      ExcludeKeywords     []string `json:"exclude_keywords"`
      MinAnonymization    int      `json:"min_anonymization"`    // Min repos before sharing
  }
  
  type crossRepoAnalyzerImpl struct {
      patternStore     storage.PatternStorage
      insightStore     storage.InsightStorage
      similarityCache  cache.Cache
      mpcClient        *mcp.Client
      privacySettings  map[string]*PrivacySettings
      logger           *slog.Logger
  }
  
  func NewCrossRepoAnalyzer(deps CrossRepoDeps) CrossRepoAnalyzer {
      return &crossRepoAnalyzerImpl{
          patternStore:     deps.PatternStore,
          insightStore:     deps.InsightStore,
          similarityCache:  deps.Cache,
          mpcClient:        deps.MCPClient,
          privacySettings:  make(map[string]*PrivacySettings),
          logger:           deps.Logger,
      }
  }
  
  func (a *crossRepoAnalyzerImpl) AnalyzeCrossRepoPatterns(
      ctx context.Context,
      repository string,
  ) ([]*CrossRepoInsight, error) {
      // Get repository characteristics
      repoChars, err := a.getRepositoryCharacteristics(ctx, repository)
      if err != nil {
          return nil, err
      }
      
      // Find similar repositories
      similarRepos, err := a.FindSimilarRepositories(ctx, repository, 20)
      if err != nil {
          return nil, err
      }
      
      // Aggregate patterns from similar repositories
      aggregatedPatterns := make(map[string]*AggregatedPattern)
      
      for _, simRepo := range similarRepos {
          if simRepo.Score < 0.7 { // Only highly similar repos
              continue
          }
          
          // Get patterns from similar repository (with privacy check)
          patterns, err := a.getShareablePatterns(ctx, simRepo.RepositoryB)
          if err != nil {
              a.logger.Warn("failed to get patterns", 
                  slog.String("repo", simRepo.RepositoryB),
                  slog.Any("error", err))
              continue
          }
          
          // Aggregate patterns
          for _, pattern := range patterns {
              key := a.generatePatternKey(pattern)
              if agg, exists := aggregatedPatterns[key]; exists {
                  agg.Merge(pattern, simRepo.Score)
              } else {
                  aggregatedPatterns[key] = a.newAggregatedPattern(pattern)
              }
          }
      }
      
      // Generate insights from aggregated patterns
      var insights []*CrossRepoInsight
      
      for _, aggPattern := range aggregatedPatterns {
          if aggPattern.SourceCount < 3 { // Need at least 3 sources
              continue
          }
          
          insight := a.generateInsight(aggPattern, repoChars)
          if insight != nil && insight.Confidence > 0.6 {
              insights = append(insights, insight)
          }
      }
      
      // Rank insights by relevance and impact
      insights = a.rankInsights(insights, repoChars)
      
      // Store insights for caching
      for _, insight := range insights {
          a.insightStore.Create(ctx, insight)
      }
      
      return insights, nil
  }
  
  func (a *crossRepoAnalyzerImpl) FindSimilarRepositories(
      ctx context.Context,
      repository string,
      limit int,
  ) ([]*RepositorySimilarity, error) {
      // Check cache
      cacheKey := fmt.Sprintf("similar_repos:%s", repository)
      if cached, found := a.similarityCache.Get(cacheKey); found {
          return cached.([]*RepositorySimilarity), nil
      }
      
      // Call MCP server for multi-repo analysis
      response, err := a.mpcClient.Call(ctx, "memory_analyze", map[string]interface{}{
          "operation": "find_similar_repositories",
          "options": map[string]interface{}{
              "repository": repository,
              "session_id": uuid.New().String(),
          },
      })
      if err != nil {
          return nil, err
      }
      
      // Parse response into similarity scores
      var similarities []*RepositorySimilarity
      for _, item := range response.SimilarRepositories {
          similarity := &RepositorySimilarity{
              RepositoryA:    repository,
              RepositoryB:    item.Repository,
              Score:          item.Score,
              Dimensions:     a.parseDimensions(item.Dimensions),
              SharedPatterns: item.SharedPatterns,
              LastCalculated: time.Now(),
          }
          similarities = append(similarities, similarity)
      }
      
      // Sort by score
      sort.Slice(similarities, func(i, j int) bool {
          return similarities[i].Score > similarities[j].Score
      })
      
      // Limit results
      if len(similarities) > limit {
          similarities = similarities[:limit]
      }
      
      // Cache results
      a.similarityCache.Set(cacheKey, similarities, 1*time.Hour)
      
      return similarities, nil
  }
  
  func (a *crossRepoAnalyzerImpl) generateInsight(
      pattern *AggregatedPattern,
      repoChars *RepositoryCharacteristics,
  ) *CrossRepoInsight {
      // Determine insight type
      insightType := a.classifyInsightType(pattern)
      
      // Calculate relevance to current repository
      relevance := a.calculateRelevance(pattern, repoChars)
      
      // Generate actionable recommendations
      recommendations := a.generateRecommendations(pattern, repoChars)
      
      // Calculate impact metrics
      impact := a.calculateImpact(pattern)
      
      insight := &CrossRepoInsight{
          ID:          uuid.New().String(),
          Type:        insightType,
          Title:       a.generateInsightTitle(pattern),
          Description: a.generateInsightDescription(pattern),
          Pattern: &AnonymizedPattern{
              Type:           pattern.Type,
              Sequence:       a.anonymizeSequence(pattern.Sequence),
              Frequency:      pattern.Frequency,
              SuccessRate:    pattern.SuccessRate,
              TimeMetrics:    pattern.TimeMetrics,
              CommonKeywords: a.filterSensitiveKeywords(pattern.Keywords),
              ProjectTypes:   pattern.ProjectTypes,
          },
          SourceCount:     pattern.SourceCount,
          Confidence:      pattern.Confidence,
          Relevance:       relevance,
          Impact:          impact,
          Applicability:   pattern.ProjectTypes,
          Prerequisites:   a.identifyPrerequisites(pattern),
          Recommendations: recommendations,
          Tags:            a.generateTags(pattern),
          Metadata:        make(map[string]interface{}),
          GeneratedAt:     time.Now(),
          ValidUntil:      time.Now().Add(30 * 24 * time.Hour),
          IsActionable:    len(recommendations) > 0,
      }
      
      return insight
  }
  
  func (a *crossRepoAnalyzerImpl) ContributePattern(
      ctx context.Context,
      pattern *TaskPattern,
      optIn bool,
  ) error {
      if !optIn {
          return nil // User opted out
      }
      
      // Get privacy settings for repository
      settings := a.getPrivacySettings(pattern.Repository)
      if !settings.SharePatterns {
          return nil
      }
      
      // Anonymize pattern
      anonymized := a.anonymizePattern(pattern, settings)
      
      // Send to server for aggregation
      _, err := a.mpcClient.Call(ctx, "memory_create", map[string]interface{}{
          "operation": "contribute_pattern",
          "options": map[string]interface{}{
              "pattern":    anonymized,
              "repository": "cross_repo_learning", // Special repo for shared patterns
          },
      })
      
      return err
  }
  
  func (a *crossRepoAnalyzerImpl) anonymizePattern(
      pattern *TaskPattern,
      settings *PrivacySettings,
  ) *TaskPattern {
      // Create copy
      anonymized := *pattern
      
      // Remove repository identifier
      anonymized.Repository = "anonymous"
      
      // Filter keywords
      var filteredKeywords []string
      for _, keyword := range pattern.Metadata["keywords"].([]string) {
          if !a.isSensitive(keyword, settings.ExcludeKeywords) {
              filteredKeywords = append(filteredKeywords, keyword)
          }
      }
      anonymized.Metadata["keywords"] = filteredKeywords
      
      // Generalize task content
      for i, step := range anonymized.Sequence {
          anonymized.Sequence[i].TaskType = a.generalizeTaskType(step.TaskType)
          anonymized.Sequence[i].Keywords = a.filterKeywords(step.Keywords, settings)
      }
      
      // Remove specific metadata
      delete(anonymized.Metadata, "user_id")
      delete(anonymized.Metadata, "team_id")
      delete(anonymized.Metadata, "project_name")
      
      return &anonymized
  }
  ```

- **Configuration Changes:** 
  - Add privacy settings for pattern sharing
  - Configure similarity calculation weights
  - Set minimum anonymization thresholds
  - Add cross-repo learning opt-in/out

- **Dependencies:**
  - MCP client for server communication
  - Caching for similarity scores
  - Privacy controls implementation

## 4. Acceptance Criteria
- **Functional Criteria:**
  - Cross-repo insights have >60% relevance score
  - Repository similarity calculation is accurate
  - Privacy controls prevent sensitive data leakage
  - Pattern anonymization works correctly
  - Insights are actionable and specific
  - Similar repository recommendations are relevant
  - Opt-in/out controls function properly
  
- **Technical Criteria:**
  - Insight generation completes in <10 seconds
  - Similarity calculations are cached effectively
  - Privacy controls enforced at all levels
  - Scalable to thousands of repositories
  
- **Integration Criteria:**
  - Works with MCP server for multi-repo data
  - Integrates with pattern detection engine
  - Compatible with suggestion service
  
- **Test Criteria:**
  - Privacy controls thoroughly tested
  - Similarity algorithms validated
  - Insight quality verified
  - Anonymization effectiveness confirmed

## 5. Testing Requirements
- **Unit Tests:**
  - Pattern anonymization logic
  - Similarity calculation algorithms
  - Privacy control enforcement
  - Insight generation logic
  - Keyword filtering
  - Impact calculations
  
- **Integration Tests:**
  - Cross-repo analysis flow
  - MCP server communication
  - Privacy settings application
  - Caching effectiveness
  
- **Manual Testing:**
  - Verify insight relevance
  - Check privacy protection
  - Test opt-in/out flows
  - Validate similar repo suggestions
  
- **Test Data:**
  - Multiple repository samples
  - Sensitive pattern examples
  - Privacy setting scenarios
  - Similarity test cases

## 6. Definition of Done
- **Code Complete:** Cross-repo learning with privacy controls implemented
- **Tests Passing:** All unit and integration tests passing (≥85% coverage)
- **Documentation Updated:** Privacy policy and usage documentation complete
- **Integration Verified:** Works with MCP server and pattern system
- **Review Approved:** Security and privacy review completed

## 7. Dependencies and Blockers
- **Required Sub-Tasks:** ST-MT-004-001 (Pattern Detection Engine)
- **External Dependencies:** MCP server with multi-repo support
- **Environmental Requirements:** Access to multiple repositories for testing
- **Potential Blockers:** Privacy concerns may limit data sharing

## 8. Integration Notes
- **Component Interfaces:** Used by CLI insights command and suggestion service
- **Data Flow:** Local Patterns → Anonymization → Server Aggregation → Insights
- **Error Handling:** Graceful degradation when repos opt out
- **Configuration Impact:** New privacy settings section