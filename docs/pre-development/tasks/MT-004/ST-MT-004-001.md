# ST-MT-004-001: Create Pattern Detection Engine and Analytics Foundation

## 1. Sub-Task Overview
- **Sub-Task ID:** ST-MT-004-001
- **Sub-Task Name:** Create Pattern Detection Engine and Analytics Foundation
- **Parent Task:** MT-004: Intelligence Features and Pattern Learning
- **Estimated Duration:** 4 hours
- **Implementation Type:** Code

## 2. Deliverable Specification
- **Primary Output:** Pattern detection engine with core analytics structures and algorithms
- **Code Location:** 
  - `cli/internal/domain/entities/patterns.go` - Pattern entities and structures
  - `cli/internal/domain/services/pattern_detector.go` - Pattern detection service
  - `cli/internal/adapters/secondary/analytics/engine.go` - Analytics engine
  - `cli/internal/domain/entities/session.go` - Session tracking entities
- **Technical Requirements:** Go pattern matching algorithms, time-series analysis, statistical calculations
- **Interface Definition:** PatternDetector interface, AnalyticsEngine interface, pattern scoring models

## 3. Implementation Details
- **Step-by-Step Approach:**
  1. Create pattern entity structures (TaskPattern, WorkflowPattern, SequencePattern)
  2. Implement session tracking entity with productivity metrics
  3. Create pattern detection service interface and base implementation
  4. Implement sequence detection algorithm for task completion patterns
  5. Add time-based pattern analysis (daily, weekly patterns)
  6. Create analytics engine for productivity calculations
  7. Implement pattern scoring and confidence algorithms
  8. Add pattern persistence layer interface
  9. Create pattern matching utilities
  10. Add statistical analysis functions

- **Code Examples:**
  ```go
  // Pattern entities
  package entities
  
  type PatternType string
  
  const (
      PatternTypeSequence   PatternType = "sequence"
      PatternTypeWorkflow   PatternType = "workflow"
      PatternTypeTemporal   PatternType = "temporal"
      PatternTypeProject    PatternType = "project"
  )
  
  type TaskPattern struct {
      ID           string                 `json:"id" validate:"required,uuid"`
      Type         PatternType            `json:"type" validate:"required"`
      Name         string                 `json:"name" validate:"required,min=1,max=200"`
      Description  string                 `json:"description"`
      Sequence     []PatternStep          `json:"sequence"`
      Frequency    float64                `json:"frequency"`    // How often this pattern occurs
      Confidence   float64                `json:"confidence"`   // Confidence score 0-1
      SuccessRate  float64                `json:"success_rate"` // Completion success rate
      Repository   string                 `json:"repository"`
      ProjectType  string                 `json:"project_type,omitempty"`
      Metadata     map[string]interface{} `json:"metadata"`
      FirstSeen    time.Time              `json:"first_seen"`
      LastSeen     time.Time              `json:"last_seen"`
      Occurrences  int                    `json:"occurrences"`
  }
  
  type PatternStep struct {
      Order       int                    `json:"order"`
      TaskType    string                 `json:"task_type"`     // Type of task (feature, bug, refactor)
      Keywords    []string               `json:"keywords"`      // Common keywords
      Duration    *DurationStats         `json:"duration"`      // Time statistics
      Priority    string                 `json:"priority,omitempty"`
      Metadata    map[string]interface{} `json:"metadata"`
  }
  
  type DurationStats struct {
      Average   time.Duration `json:"average"`
      Min       time.Duration `json:"min"`
      Max       time.Duration `json:"max"`
      StdDev    time.Duration `json:"std_dev"`
      Samples   int           `json:"samples"`
  }
  
  // Pattern detection service
  package services
  
  type PatternDetector interface {
      DetectSequencePatterns(ctx context.Context, tasks []*Task, minSupport float64) ([]*TaskPattern, error)
      DetectWorkflowPatterns(ctx context.Context, repository string, timeRange TimeRange) ([]*TaskPattern, error)
      DetectTemporalPatterns(ctx context.Context, sessions []*Session) ([]*TaskPattern, error)
      CalculatePatternScore(pattern *TaskPattern, newSequence []*Task) float64
      UpdatePatternStatistics(ctx context.Context, pattern *TaskPattern, outcome PatternOutcome) error
  }
  
  type patternDetectorImpl struct {
      taskStore     storage.TaskStorage
      patternStore  storage.PatternStorage
      analytics     AnalyticsEngine
      logger        *slog.Logger
      minOccurrence int
      minConfidence float64
  }
  
  func NewPatternDetector(
      taskStore storage.TaskStorage,
      patternStore storage.PatternStorage,
      analytics AnalyticsEngine,
      logger *slog.Logger,
  ) PatternDetector {
      return &patternDetectorImpl{
          taskStore:     taskStore,
          patternStore:  patternStore,
          analytics:     analytics,
          logger:        logger,
          minOccurrence: 3,      // Minimum times pattern must occur
          minConfidence: 0.6,    // Minimum confidence score
      }
  }
  
  func (p *patternDetectorImpl) DetectSequencePatterns(
      ctx context.Context, 
      tasks []*Task, 
      minSupport float64,
  ) ([]*TaskPattern, error) {
      // Group tasks by completion time windows
      sequences := p.extractTaskSequences(tasks)
      
      // Find frequent patterns using modified Apriori algorithm
      patterns := make(map[string]*TaskPattern)
      
      for _, seq := range sequences {
          subSeqs := p.generateSubsequences(seq, 2, 5) // 2-5 task patterns
          
          for _, subSeq := range subSeqs {
              key := p.generatePatternKey(subSeq)
              
              if pattern, exists := patterns[key]; exists {
                  pattern.Occurrences++
                  p.updatePatternStats(pattern, subSeq)
              } else {
                  pattern := p.createPatternFromSequence(subSeq)
                  if pattern != nil {
                      patterns[key] = pattern
                  }
              }
          }
      }
      
      // Filter by support and confidence
      var results []*TaskPattern
      totalSequences := float64(len(sequences))
      
      for _, pattern := range patterns {
          support := float64(pattern.Occurrences) / totalSequences
          if support >= minSupport && pattern.Confidence >= p.minConfidence {
              pattern.Frequency = support
              results = append(results, pattern)
          }
      }
      
      // Sort by frequency and confidence
      sort.Slice(results, func(i, j int) bool {
          if results[i].Frequency == results[j].Frequency {
              return results[i].Confidence > results[j].Confidence
          }
          return results[i].Frequency > results[j].Frequency
      })
      
      return results, nil
  }
  
  // Analytics engine
  type AnalyticsEngine interface {
      CalculateProductivityScore(session *Session) float64
      GetTaskCompletionTrends(ctx context.Context, repository string, days int) (*CompletionTrends, error)
      AnalyzeTaskDurations(tasks []*Task) *DurationAnalysis
      DetectBottlenecks(ctx context.Context, workflows []*TaskPattern) ([]*Bottleneck, error)
  }
  
  type analyticsEngineImpl struct {
      taskStore  storage.TaskStorage
      calculator *ProductivityCalculator
      logger     *slog.Logger
  }
  
  func (a *analyticsEngineImpl) CalculateProductivityScore(session *Session) float64 {
      // Calculate based on:
      // - Tasks completed vs started
      // - Time efficiency (actual vs estimated)
      // - Priority distribution
      // - Focus time (continuous work periods)
      
      completionRate := float64(session.TasksCompleted) / float64(session.TasksStarted)
      priorityScore := a.calculatePriorityScore(session.TasksByPriority)
      efficiencyScore := a.calculateEfficiencyScore(session.TaskDurations)
      focusScore := a.calculateFocusScore(session.WorkPeriods)
      
      // Weighted average
      return (completionRate * 0.3) + 
             (priorityScore * 0.2) + 
             (efficiencyScore * 0.3) + 
             (focusScore * 0.2)
  }
  ```

- **Configuration Changes:** 
  - Add pattern detection configuration settings
  - Configure minimum support and confidence thresholds
  - Set analytics calculation intervals

- **Dependencies:**
  - Statistical analysis libraries (gonum/stat)
  - Time series analysis utilities

## 4. Acceptance Criteria
- **Functional Criteria:**
  - Pattern detection identifies common task sequences with >70% accuracy
  - Analytics engine calculates productivity scores correctly
  - Session tracking captures all relevant metrics
  - Pattern scoring algorithm produces consistent results
  - Temporal patterns detected (daily/weekly rhythms)
  - Pattern confidence scores are meaningful
  
- **Technical Criteria:**
  - Pattern detection completes in <5 seconds for 1000 tasks
  - Memory efficient for large datasets
  - Algorithms handle edge cases gracefully
  - Statistical calculations are accurate
  - Pattern storage is optimized
  
- **Integration Criteria:**
  - Integrates with existing task storage
  - Works with session tracking from CLI
  - Pattern data accessible to suggestion service
  
- **Test Criteria:**
  - Pattern detection accuracy validated
  - Analytics calculations verified
  - Performance benchmarks met
  - Edge cases handled properly

## 5. Testing Requirements
- **Unit Tests:**
  - Pattern detection algorithm correctness
  - Sequence extraction logic
  - Statistical calculations accuracy
  - Pattern scoring functions
  - Session metric calculations
  - Confidence score algorithms
  
- **Integration Tests:**
  - Pattern detection with real task data
  - Analytics engine with multiple repositories
  - Session tracking integration
  - Pattern persistence and retrieval
  
- **Manual Testing:**
  - Verify patterns make intuitive sense
  - Check analytics dashboard accuracy
  - Validate productivity scores
  
- **Test Data:**
  - Synthetic task sequences with known patterns
  - Historical task data samples
  - Edge case scenarios (single tasks, gaps)

## 6. Definition of Done
- **Code Complete:** Pattern detection and analytics engine fully implemented
- **Tests Passing:** All unit and integration tests passing (≥85% coverage)
- **Documentation Updated:** Algorithm documentation and API docs complete
- **Integration Verified:** Works with existing task management system
- **Review Approved:** Code review by senior developer completed

## 7. Dependencies and Blockers
- **Required Sub-Tasks:** None (foundational for MT-004)
- **External Dependencies:** Statistical analysis libraries
- **Environmental Requirements:** Go 1.23+ development environment
- **Potential Blockers:** Algorithm complexity for large datasets

## 8. Integration Notes
- **Component Interfaces:** Used by suggestion service and template system
- **Data Flow:** Tasks → Pattern Detection → Pattern Storage → Suggestions
- **Error Handling:** Graceful handling of insufficient data
- **Configuration Impact:** New pattern detection settings added