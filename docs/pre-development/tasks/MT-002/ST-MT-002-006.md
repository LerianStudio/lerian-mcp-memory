# ST-MT-002-006: Implement Integration Tests for Complete Automation Workflow

## 1. Sub-Task Overview
- **Sub-Task ID:** ST-MT-002-006
- **Sub-Task Name:** Implement Integration Tests for Complete Automation Workflow
- **Parent Task:** MT-002: AI-Powered Development Automation with Document Generation
- **Estimated Duration:** 5 hours
- **Implementation Type:** Testing

## 2. Deliverable Specification
- **Primary Output:** Comprehensive integration test suite for complete document generation workflow
- **Code Location:** 
  - `cli/tests/integration/` - Integration tests
  - `cli/tests/e2e/` - End-to-end workflow tests
  - `cli/tests/automation/` - Document automation tests
- **Technical Requirements:** Test framework, mock services, workflow testing, rule validation
- **Interface Definition:** Test suite covering complete PRD → TRD → Tasks automation workflow

## 3. Implementation Details
- **Step-by-Step Approach:**
  1. Setup integration test framework for document automation
  2. Create mock implementations for all services
  3. Implement complete workflow tests (PRD → Sub-tasks)
  4. Test interactive PRD creation flow
  5. Test TRD generation from PRDs
  6. Test main task and sub-task generation
  7. Test rule management and customization
  8. Test document chain orchestration
  9. Create REPL mode integration tests
  10. Add CLI command integration tests for all new commands
  11. Setup performance testing for complete workflows

- **Code Examples:**
  ```go
  // AI-powered integration test suite
  package integration
  
  import (
      "context"
      "encoding/json"
      "os"
      "path/filepath"
      "testing"
      "time"
      
      "github.com/stretchr/testify/assert"
      "github.com/stretchr/testify/require"
      "github.com/stretchr/testify/suite"
  )
  
  type AIIntegrationSuite struct {
      suite.Suite
      container      *Container
      tempDir        string
      mockAIService  *MockAIService
      mockREPLServer *MockREPLServer
      testPRDPath    string
  }
  
  func (s *AIIntegrationSuite) SetupSuite() {
      // Create temporary directory for test isolation
      tempDir, err := os.MkdirTemp("", "lmmc-ai-test-*")
      s.Require().NoError(err)
      s.tempDir = tempDir
      
      // Setup test PRD file
      s.testPRDPath = s.createTestPRD()
      
      // Setup mock AI service
      s.mockAIService = NewMockAIService()
      s.mockREPLServer = NewMockREPLServer()
      
      // Initialize container with test configuration
      s.container, err = s.setupTestContainer()
      s.Require().NoError(err)
  }
  
  func (s *AIIntegrationSuite) TearDownSuite() {
      if s.mockREPLServer != nil {
          s.mockREPLServer.Stop()
      }
      os.RemoveAll(s.tempDir)
  }
  
  func (s *AIIntegrationSuite) SetupTest() {
      // Reset mock services for each test
      s.mockAIService.Reset()
      s.mockREPLServer.Reset()
  }
  
  func (s *AIIntegrationSuite) createTestPRD() string {
      prdContent := `# User Authentication System PRD
  
  ## Overview
  This document outlines the requirements for implementing a comprehensive user authentication system.
  
  ## Features
  
  ### Core Authentication
  - User registration with email verification
  - Secure login with password hashing
  - JWT token-based session management
  - Password reset functionality
  
  ### Security Features
  - Two-factor authentication (2FA)
  - Rate limiting for login attempts
  - Account lockout after failed attempts
  - Audit logging for security events
  
  ### Integration Requirements
  - OAuth 2.0 integration (Google, GitHub)
  - LDAP/Active Directory support
  - SSO (Single Sign-On) capabilities
  
  ## Technical Requirements
  - Database: PostgreSQL for user data
  - Redis for session storage
  - Email service integration
  - HTTPS enforcement
  - Password complexity validation
  
  ## Acceptance Criteria
  - Users can register and verify accounts
  - Secure login/logout functionality
  - Password reset works via email
  - 2FA can be enabled/disabled
  - OAuth integration works seamlessly
  `
      
      testFile := filepath.Join(s.tempDir, "test-prd.md")
      err := os.WriteFile(testFile, []byte(prdContent), 0644)
      s.Require().NoError(err)
      
      return testFile
  }
  
  func (s *AIIntegrationSuite) setupTestContainer() (*Container, error) {
      // Create test configuration with mock AI service
      config := &Config{
          Server: struct {
              URL     string `mapstructure:"url"`
              Version string `mapstructure:"version"`
              Timeout int    `mapstructure:"timeout"`
          }{
              URL:     "http://localhost:9080",
              Timeout: 30,
          },
          AI: struct {
              PrimaryModel   string   `mapstructure:"primary_model"`
              FallbackModels []string `mapstructure:"fallback_models"`
              CacheEnabled   bool     `mapstructure:"cache_enabled"`
              MaxRetries     int      `mapstructure:"max_retries"`
          }{
              PrimaryModel:   "mock",
              FallbackModels: []string{"mock-fallback"},
              CacheEnabled:   true,
              MaxRetries:     3,
          },
          REPL: struct {
              Port       int  `mapstructure:"port"`
              EnableHTTP bool `mapstructure:"enable_http"`
          }{
              Port:       8080,
              EnableHTTP: true,
          },
      }
      
      // Initialize container with mock services
      container := &Container{
          Config:        config,
          AIService:     s.mockAIService,
          FileProcessor: NewLocalFileProcessor(nil),
          TaskGenerator: NewDefaultTaskGenerator(nil, nil),
          REPL:         NewTestREPL(config.REPL, nil),
      }
      
      return container, nil
  }
  
  // Complete document automation workflow test
  func (s *AIIntegrationSuite) TestCompleteAutomationWorkflow() {
      // Setup mock responses for complete chain
      s.mockAIService.SetupInteractiveSession(&InteractiveSession{
          ID:    "test-session",
          Type:  DocumentTypePRD,
          State: SessionStateActive,
      })
      
      s.mockDocumentGenerator.SetupPRDResponse(&PRD{
          Document: Document{
              ID:      "test-prd",
              Name:    "Test Product Requirements",
              Content: "Generated PRD content...",
              Type:    DocumentTypePRD,
          },
      })
      
      s.mockDocumentGenerator.SetupTRDResponse(&TRD{
          Document: Document{
              ID:      "test-trd",
              Name:    "Technical Requirements for Test Product",
              Content: "Generated TRD content...",
              Type:    DocumentTypeTRD,
          },
          PRDReference: "test-prd",
          TechStack:   []string{"Go", "PostgreSQL", "Redis"},
      })
      
      s.mockTaskGenerator.SetupMainTasksResponse([]*MainTask{
          {
              ID:               "MT-001",
              Name:             "Foundation Setup",
              Phase:            "Foundation",
              Duration:         "2-3 weeks",
              AtomicValidation: true,
          },
          {
              ID:               "MT-002",
              Name:             "Core Features",
              Phase:            "Core",
              Duration:         "3-4 weeks",
              AtomicValidation: true,
          },
      })
      
      s.mockTaskGenerator.SetupSubTasksResponse([]*SubTask{
          {
              ID:           "ST-MT-001-001",
              ParentTaskID: "MT-001",
              Name:        "Setup Project Structure",
              Duration:     3,
              Type:        "Code",
          },
          {
              ID:           "ST-MT-001-002",
              ParentTaskID: "MT-001",
              Name:        "Configure Database",
              Duration:     4,
              Type:        "Configuration",
          },
      })
      
      // Execute complete workflow
      result, err := s.container.DocumentChain.ExecuteFullChain("Create a user authentication system")
      s.Require().NoError(err)
      
      // Verify PRD creation
      s.Assert().NotNil(result.PRD)
      s.Assert().Equal("test-prd", result.PRD.ID)
      s.Assert().Contains(result.PRD.Content, "Generated PRD content")
      
      // Verify TRD generation
      s.Assert().NotNil(result.TRD)
      s.Assert().Equal("test-trd", result.TRD.ID)
      s.Assert().Equal("test-prd", result.TRD.PRDReference)
      s.Assert().Contains(result.TRD.TechStack, "Go")
      
      // Verify main tasks
      s.Assert().Len(result.MainTasks, 2)
      s.Assert().Equal("MT-001", result.MainTasks[0].ID)
      s.Assert().True(result.MainTasks[0].AtomicValidation)
      
      // Verify sub-tasks
      s.Assert().Len(result.SubTasks, 2)
      s.Assert().Equal("ST-MT-001-001", result.SubTasks[0].ID)
      s.Assert().Equal("MT-001", result.SubTasks[0].ParentTaskID)
      s.Assert().LessOrEqual(result.SubTasks[0].Duration, 4)
  }
  
  // Test interactive PRD creation flow
  func (s *AIIntegrationSuite) TestInteractivePRDCreation() {
      // Setup interactive session responses
      s.mockAIService.SetupInteractiveResponses([]SessionResponse{
          {Content: "What is the main purpose of your product?"},
          {Content: "Who are your target users?"},
          {Content: "What are the key features you want to include?"},
          {Content: "Great! I'll now generate your PRD."},
      })
      
      // Simulate user inputs
      userInputs := []string{
          "Create a task management system for developers",
          "Software developers and project managers",
          "Task creation, assignment, tracking, and reporting",
      }
      
      // Execute interactive PRD creation
      session, err := s.container.AIService.StartInteractiveSession(DocumentTypePRD)
      s.Require().NoError(err)
      
      for i, input := range userInputs {
          response, err := s.container.AIService.ContinueSession(session.ID, input)
          s.Require().NoError(err)
          s.Assert().NotEmpty(response.Content)
      }
      
      // Generate final PRD
      context := &GenerationContext{
          Type:       DocumentTypePRD,
          UserInputs: userInputs,
          Repository: "test-repo",
      }
      
      prd, err := s.container.DocumentGenerator.GeneratePRD(context)
      s.Require().NoError(err)
      s.Assert().NotNil(prd)
      s.Assert().Contains(prd.Content, "task management")
  }
  
  // Test rule customization and application
  func (s *AIIntegrationSuite) TestRuleCustomization() {
      // Load default rule
      defaultRule, err := s.container.RuleManager.GetRule(RuleTypePRD)
      s.Require().NoError(err)
      s.Assert().True(defaultRule.IsDefault)
      
      // Create custom rule
      customRule := &Rule{
          ID:      "custom-prd",
          Name:    "Custom PRD Rule",
          Type:    RuleTypePRD,
          Content: "Custom PRD generation template...",
          IsCustom: true,
      }
      
      // Set custom rule
      err = s.container.RuleManager.SetCustomRule(customRule)
      s.Require().NoError(err)
      
      // Verify custom rule is used
      activeRule, err := s.container.RuleManager.GetRule(RuleTypePRD)
      s.Require().NoError(err)
      s.Assert().Equal("custom-prd", activeRule.ID)
      s.Assert().True(activeRule.IsCustom)
      
      // Generate PRD with custom rule
      context := &GenerationContext{
          Type: DocumentTypePRD,
          Rule: activeRule,
      }
      
      prd, err := s.container.DocumentGenerator.GeneratePRD(context)
      s.Require().NoError(err)
      s.Assert().NotNil(prd)
      s.Assert().Equal("custom-prd", prd.GeneratedBy)
  }
  
  // Complete PRD processing workflow test
  func (s *AIIntegrationSuite) TestCompleteWorkflow() {
      // Setup mock AI responses
      s.mockAIService.SetupAnalysisResponse(&AIAnalysis{
          ID:       "test-analysis-1",
          PRDID:    "test-prd-1",
          Summary:  "User authentication system with security features",
          KeyFeatures: []string{
              "User registration with email verification",
              "Secure login with JWT tokens",
              "Two-factor authentication",
              "OAuth 2.0 integration",
              "Password reset functionality",
          },
          TechnicalReqs: []string{
              "PostgreSQL database integration",
              "Redis session storage",
              "Email service configuration",
              "HTTPS enforcement",
          },
          Complexity: ComplexityEstimate{
              Overall:        "high",
              Score:          7.5,
              EstimatedHours: 120,
              Confidence:     0.85,
          },
      })
      
      // Step 1: Import PRD
      fileProcessor := s.container.FileProcessor
      prd, err := fileProcessor.ProcessFile(s.testPRDPath)
      s.Require().NoError(err)
      s.Assert().Equal("User Authentication System PRD", prd.Metadata.Title)
      s.Assert().Greater(prd.Metadata.WordCount, 100)
      s.Assert().Equal("high", prd.Metadata.EstimatedComplexity)
      
      // Step 2: AI Analysis
      analysis, err := s.container.AIService.ParsePRD(prd)
      s.Require().NoError(err)
      s.Assert().Equal("test-analysis-1", analysis.ID)
      s.Assert().Len(analysis.KeyFeatures, 5)
      s.Assert().Len(analysis.TechnicalReqs, 4)
      s.Assert().Equal("high", analysis.Complexity.Overall)
      
      // Step 3: Task Generation
      context := GenerationContext{
          Repository:  "test-repo",
          ProjectType: "web-application",
      }
      
      tasks, err := s.container.TaskGenerator.GenerateFromAnalysis(analysis, context)
      s.Require().NoError(err)
      s.Assert().Greater(len(tasks), 5)
      
      // Verify task quality
      for _, task := range tasks {
          s.Assert().NotEmpty(task.Content)
          s.Assert().NotEmpty(task.Priority)
          s.Assert().Greater(task.EstimatedHours, 0)
          s.Assert().Equal("test-repo", task.Repository)
      }
      
      // Step 4: Verify task complexity distribution
      complexityCounts := make(map[string]int)
      for _, task := range tasks {
          if complexity, ok := task.Metadata["complexity"].(string); ok {
              complexityCounts[complexity]++
          }
      }
      
      s.Assert().Greater(complexityCounts["high"], 0, "Should have high complexity tasks")
      s.Assert().Greater(complexityCounts["medium"], 0, "Should have medium complexity tasks")
  }
  
  // AI service fallback testing
  func (s *AIIntegrationSuite) TestAIServiceFallback() {
      // Configure primary model to fail
      s.mockAIService.SetPrimaryModelFailure(true)
      s.mockAIService.SetFallbackResponse(&AIAnalysis{
          ID:      "fallback-analysis",
          Summary: "Fallback analysis successful",
      })
      
      // Create test PRD
      prd := &PRD{
          ID:      "test-prd",
          Content: "Simple test document",
          Format:  FormatMarkdown,
      }
      
      // Should succeed with fallback model
      analysis, err := s.container.AIService.ParsePRD(prd)
      s.Require().NoError(err)
      s.Assert().Equal("fallback-analysis", analysis.ID)
      s.Assert().True(s.mockAIService.FallbackWasUsed())
  }
  
  // REPL integration testing
  func (s *AIIntegrationSuite) TestREPLIntegration() {
      repl := s.container.REPL
      repl.SetAIService(s.container.AIService)
      repl.SetTaskService(s.container.TaskService)
      
      // Test AI query command
      s.mockAIService.SetQueryResponse("Test AI response")
      
      response, err := repl.HandleCommand("ai How do I implement authentication?")
      s.Require().NoError(err)
      s.Assert().Contains(response, "Test AI response")
      
      // Test PRD import command
      response, err = repl.HandleCommand(fmt.Sprintf("prd import %s", s.testPRDPath))
      s.Require().NoError(err)
      s.Assert().Contains(response, "imported successfully")
      
      // Test task generation command
      s.mockAIService.SetupAnalysisResponse(&AIAnalysis{
          ID: "repl-analysis",
          KeyFeatures: []string{"Feature 1", "Feature 2"},
      })
      
      response, err = repl.HandleCommand("generate")
      s.Require().NoError(err)
      s.Assert().Contains(response, "generated")
  }
  
  // CLI command integration tests
  func (s *AIIntegrationSuite) TestCLICommands() {
      // Build CLI binary for testing
      binaryPath := s.buildTestBinary()
      defer os.Remove(binaryPath)
      
      // Test PRD import command
      output, err := s.runCLICommand(binaryPath, "prd", "import", s.testPRDPath)
      s.Require().NoError(err)
      s.Assert().Contains(output, "imported successfully")
      
      // Test PRD list command
      output, err = s.runCLICommand(binaryPath, "prd", "list")
      s.Require().NoError(err)
      s.Assert().Contains(output, "User Authentication System PRD")
      
      // Test task generation
      s.mockAIService.SetupAnalysisResponse(&AIAnalysis{
          KeyFeatures: []string{"CLI Test Feature"},
      })
      
      output, err = s.runCLICommand(binaryPath, "prd", "generate", "--max-tasks", "5")
      s.Require().NoError(err)
      s.Assert().Contains(output, "generated")
  }
  
  // Performance testing for AI operations
  func (s *AIIntegrationSuite) TestAIPerformance() {
      // Create larger PRD for performance testing
      largePRD := s.createLargePRD()
      
      // Test processing time
      start := time.Now()
      prd, err := s.container.FileProcessor.ProcessFile(largePRD)
      s.Require().NoError(err)
      processingTime := time.Since(start)
      
      s.Assert().Less(processingTime, 5*time.Second, "File processing should be fast")
      
      // Test AI analysis time
      s.mockAIService.SetAnalysisDelay(2 * time.Second) // Simulate AI processing time
      
      start = time.Now()
      _, err = s.container.AIService.ParsePRD(prd)
      s.Require().NoError(err)
      analysisTime := time.Since(start)
      
      s.Assert().Less(analysisTime, 10*time.Second, "AI analysis should complete reasonably fast")
  }
  
  // Mock AI service for testing
  type MockAIService struct {
      analysisResponse *AIAnalysis
      queryResponse    string
      primaryFails     bool
      fallbackUsed     bool
      analysisDelay    time.Duration
      mutex           sync.RWMutex
  }
  
  func NewMockAIService() *MockAIService {
      return &MockAIService{}
  }
  
  func (m *MockAIService) SetupAnalysisResponse(analysis *AIAnalysis) {
      m.mutex.Lock()
      defer m.mutex.Unlock()
      m.analysisResponse = analysis
  }
  
  func (m *MockAIService) SetPrimaryModelFailure(fails bool) {
      m.mutex.Lock()
      defer m.mutex.Unlock()
      m.primaryFails = fails
  }
  
  func (m *MockAIService) SetAnalysisDelay(delay time.Duration) {
      m.mutex.Lock()
      defer m.mutex.Unlock()
      m.analysisDelay = delay
  }
  
  func (m *MockAIService) ParsePRD(prd *PRD) (*AIAnalysis, error) {
      m.mutex.Lock()
      defer m.mutex.Unlock()
      
      // Simulate processing delay
      if m.analysisDelay > 0 {
          time.Sleep(m.analysisDelay)
      }
      
      if m.primaryFails {
          m.fallbackUsed = true
      }
      
      if m.analysisResponse == nil {
          return nil, fmt.Errorf("no mock response configured")
      }
      
      // Copy response to avoid mutation
      response := *m.analysisResponse
      response.PRDID = prd.ID
      response.ProcessedAt = time.Now()
      
      return &response, nil
  }
  
  func (m *MockAIService) FallbackWasUsed() bool {
      m.mutex.RLock()
      defer m.mutex.RUnlock()
      return m.fallbackUsed
  }
  
  func (m *MockAIService) Reset() {
      m.mutex.Lock()
      defer m.mutex.Unlock()
      m.analysisResponse = nil
      m.queryResponse = ""
      m.primaryFails = false
      m.fallbackUsed = false
      m.analysisDelay = 0
  }
  
  // Test helper methods
  func (s *AIIntegrationSuite) createLargePRD() string {
      // Generate a larger PRD for performance testing
      largePRDContent := `# Large Scale E-commerce Platform PRD
  
  ## Executive Summary
  This document outlines the requirements for building a comprehensive e-commerce platform...
  ` // Include much more content here
      
      largeFile := filepath.Join(s.tempDir, "large-prd.md")
      err := os.WriteFile(largeFile, []byte(largePRDContent), 0644)
      s.Require().NoError(err)
      
      return largeFile
  }
  
  func (s *AIIntegrationSuite) buildTestBinary() string {
      // Build binary for CLI testing
      return "path/to/test/binary"
  }
  
  func (s *AIIntegrationSuite) runCLICommand(binaryPath string, args ...string) (string, error) {
      // Execute CLI command and return output
      return "mock command output", nil
  }
  
  // Test suite runner
  func TestAIIntegration(t *testing.T) {
      suite.Run(t, new(AIIntegrationSuite))
  }
  ```

- **Configuration Changes:** None required (test-only)
- **Dependencies:**
  - Enhanced test framework for AI features
  - Mock AI service implementations
  - Performance testing utilities

## 4. Acceptance Criteria
- **Functional Criteria:**
  - Complete PRD-to-tasks workflow tested end-to-end
  - AI service fallback scenarios validated
  - REPL mode integration tested with various commands
  - CLI commands tested with real file inputs
  - Task generation quality validated with assertions
  
- **Technical Criteria:**
  - Tests are reliable and repeatable
  - Mock AI services accurately simulate real behavior
  - Performance tests validate acceptable response times
  - Error scenarios and edge cases covered
  
- **Integration Criteria:**
  - All AI feature integration points tested
  - File processing integrated with AI analysis
  - Task generation integrated with storage
  
- **Test Criteria:**
  - Test coverage ≥90% for AI feature integration
  - All user workflows validated
  - Performance benchmarks established

## 5. Testing Requirements
- **Integration Tests:**
  - Complete PRD import, analysis, and task generation workflow
  - AI service multi-model routing and fallback
  - REPL mode with AI interaction
  - CLI command integration with file processing
  - Task quality validation and acceptance criteria
  - Error handling and recovery scenarios

- **End-to-End Tests:**
  - Real file processing with various PRD formats
  - CLI binary execution with AI features
  - REPL session with interactive AI queries
  - Performance testing with large PRD documents
  
- **Performance Tests:**
  - PRD file processing time with various sizes
  - AI analysis response time simulation
  - Task generation performance with complex PRDs
  - REPL mode responsiveness testing
  
- **Test Data:** Real PRD documents, large test files, various complexity scenarios

## 6. Definition of Done
- **Code Complete:** Integration test suite covers all AI features
- **Tests Passing:** All integration and e2e tests pass consistently
- **Documentation Updated:** Test documentation and setup instructions complete
- **Integration Verified:** Tests validate complete AI workflow functionality
- **Review Approved:** Test quality and coverage review completed

## 7. Dependencies and Blockers
- **Required Sub-Tasks:** All previous MT-002 sub-tasks must be complete
- **External Dependencies:** Test framework libraries, mock service setup
- **Environmental Requirements:** Test isolation, file system access
- **Potential Blockers:** AI service response format changes, performance requirements

## 8. Integration Notes
- **Component Interfaces:** Tests all AI feature integration points
- **Data Flow:** Validates end-to-end data flow from PRD to tasks
- **Error Handling:** Tests error scenarios and recovery mechanisms
- **Configuration Impact:** Tests configuration variations and AI model settings